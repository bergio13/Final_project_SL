{"cells":[{"cell_type":"markdown","metadata":{},"source":["# LTSF Linear \n","\n","Implementation of the Linear Long Time Series Forcasting"]},{"cell_type":"markdown","metadata":{},"source":["## Imports"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-07-19T12:23:12.433127Z","iopub.status.busy":"2024-07-19T12:23:12.432797Z","iopub.status.idle":"2024-07-19T12:23:12.437889Z","shell.execute_reply":"2024-07-19T12:23:12.437199Z","shell.execute_reply.started":"2024-07-19T12:23:12.433100Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.metrics import mean_squared_error, mean_absolute_error\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","# Settings seed for reproducibility \n","np.random.seed(42)\n","\n","dataset_path = '/kaggle/input/sl-project/dataset/'"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Parameters of the model\n","lookback_window = 96\n","prediction_lengths = [96, 192, 336, 720]\n","\n","# All the datasets\n","datasets = ['weather', 'exchange_rate', 'traffic', 'electricity', 'ETTh1', 'ETTm1']"]},{"cell_type":"markdown","metadata":{},"source":["# The LTSF-Linear model"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2024-07-19T12:23:12.439399Z","iopub.status.busy":"2024-07-19T12:23:12.439154Z","iopub.status.idle":"2024-07-19T12:23:12.455116Z","shell.execute_reply":"2024-07-19T12:23:12.454377Z","shell.execute_reply.started":"2024-07-19T12:23:12.439375Z"},"trusted":true},"outputs":[],"source":["# Defining the model as a class that inherits from nn.Module\n","# Taken from https://github.com/cure-lab/LTSF-Linear/\n","\n","class LTSFLinear(nn.Module):\n","\n","    def __init__(self, loopback_window, prediction_length):\n","        super(LTSFLinear, self).__init__()\n","        self.loopback_window = loopback_window\n","        self.prediction_length = prediction_length\n","\n","        # The core of the model, a simple linear layer\n","        self.Linear = nn.Linear(self.loopback_window, self.prediction_length)\n","\n","    def forward(self, x):\n","        x = self.Linear(x.permute(0,2,1)).permute(0,2,1)\n","        return x"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2024-07-19T12:23:12.456522Z","iopub.status.busy":"2024-07-19T12:23:12.456222Z","iopub.status.idle":"2024-07-19T12:23:12.465854Z","shell.execute_reply":"2024-07-19T12:23:12.465146Z","shell.execute_reply.started":"2024-07-19T12:23:12.456495Z"},"trusted":true},"outputs":[],"source":["# Function to convert the original dataframe to numpy arrays for pythorch model training\n","\n","# Basically each element of X contains the sequence of data points of length lookback_window\n","# and the corresponding elements of y contains the sequence of data points of length prediction_length, \n","# i.e. the data points to be predicted\n","\n","\n","def build_designMatrixAndPrediction(data, lookback_window, prediction_length):\n","\n","    # Each row of X contains the sequence of data points of length lookback_window\n","    # Each row of y contains the sequence of data points of length prediction_length\n","    X = []\n","    y = []\n","\n","    for i in range(len(data)-lookback_window-prediction_length+1):\n","        X.append(data[i : i+lookback_window])\n","        y.append(data[i+lookback_window : i+lookback_window+prediction_length])\n","\n","    return np.array(X), np.array(y)"]},{"cell_type":"code","execution_count":48,"metadata":{"execution":{"iopub.execute_input":"2024-07-19T14:06:49.198150Z","iopub.status.busy":"2024-07-19T14:06:49.197742Z","iopub.status.idle":"2024-07-19T14:06:49.206582Z","shell.execute_reply":"2024-07-19T14:06:49.205879Z","shell.execute_reply.started":"2024-07-19T14:06:49.198120Z"},"trusted":true},"outputs":[],"source":["# Function to train the model with MSE Loss and Adam optimizer\n","# This is a modified version of the function provided in the github repository\n","\n","def train_model(model, X_train, y_train, epochs, batch_size):\n","\n","    # MSE Loss\n","    mse = nn.MSELoss()\n","\n","    # Optimizer\n","    optimizer = optim.Adam(model.parameters())\n","    \n","    for epoch in range(epochs):\n","        for i in range(0, len(X_train), batch_size):\n","            batch_X = X_train[i:i+batch_size]\n","            batch_y = y_train[i:i+batch_size]\n","            \n","            outputs = model(batch_X)\n","\n","            # Evaluate MSE loss and backpropagate\n","            loss = mse(outputs, batch_y)            \n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","        \n","        # Log the loss every 10 epochs\n","        if (epoch+1) % 10 == 0:\n","            print(f'Epoch [{epoch+1}/{epochs}] - Loss: {loss.item():.4f}')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Funciton to test the model\n","#  It outputts the MAE and RMSE of the model on the test data given as input\n","\n","def test_model(model, X_test, y_test):\n","    model.eval()\n","    with torch.no_grad():\n","        y_pred = model(X_test)\n","\n","    #  Reshaping the data to the original shape\n","    # before evaluating the metrics\n","    y_test_inv = y_test.reshape(-1, y_test.shape[-1])\n","    y_pred_inv = y_pred.reshape(-1, y_pred.shape[-1])\n","    \n","    mae = mean_absolute_error(y_test_inv, y_pred_inv)\n","    rmse = np.sqrt(mean_squared_error(y_test_inv, y_pred_inv))\n","    \n","    return mae, rmse, y_test_inv, y_pred_inv"]},{"cell_type":"markdown","metadata":{},"source":["# Univariate TSs\n","\n","We first train the model only on the dataset that have univariate Time Series."]},{"cell_type":"code","execution_count":47,"metadata":{"execution":{"iopub.execute_input":"2024-07-19T14:05:39.297967Z","iopub.status.busy":"2024-07-19T14:05:39.297557Z","iopub.status.idle":"2024-07-19T14:05:39.302241Z","shell.execute_reply":"2024-07-19T14:05:39.301448Z","shell.execute_reply.started":"2024-07-19T14:05:39.297934Z"},"trusted":true},"outputs":[],"source":["# Univariate TS datasets\n","\n","datasets_uni = ['exchange_rate', 'traffic', 'electricity']"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-19T14:12:06.873829Z","iopub.status.busy":"2024-07-19T14:12:06.873218Z","iopub.status.idle":"2024-07-19T14:13:40.404229Z","shell.execute_reply":"2024-07-19T14:13:40.403328Z","shell.execute_reply.started":"2024-07-19T14:12:06.873790Z"},"trusted":true},"outputs":[],"source":["# For each dataset, train the model for each prediction length\n","# and store the results in a dictionary that later will be converted into a datatframe \n","\n","results = {}\n","\n","for dataset in datasets_uni:\n","\n","    print(\"\\nDataset: \", dataset)\n","\n","    df = pd.read_csv(dataset_path + dataset + '.csv', index_col='date', parse_dates=True)\n","\n","    # Scaling all the columns in the range[0, 1]\n","    scaler = MinMaxScaler()\n","    df = pd.DataFrame(scaler.fit_transform(df), columns=df.columns, index=df.index)\n","    \n","    results[dataset] = {}\n","\n","    for pred_len in prediction_lengths:\n","\n","        print(70 * \"-\")\n","        print(f\"\\nTraining LTSF-Linear for prediction length: {pred_len}\")\n","        \n","        # Converting the dataframe to numpy arrays\n","        # such that the moel can be trained on it\n","        X, y = build_designMatrixAndPrediction(df, lookback_window, pred_len)\n","        \n","        # Splitting the data in 80% train and 20% test\n","        train_size = int(len(X) * 0.8)\n","        X_train, X_test = torch.FloatTensor(X[:train_size]), torch.FloatTensor(X[train_size:])\n","        y_train, y_test = torch.FloatTensor(y[:train_size]), torch.FloatTensor(y[train_size:])\n","        \n","        # Initializing and training the model\n","        modelLSTF = LTSFLinear(lookback_window, prediction_length = pred_len)\n","        \n","        train_model(modelLSTF, X_train, y_train, epochs = 100, batch_size = 32)\n","        \n","        # Testing the model and saving its metrics\n","        mae, rmse, y_test_inv, y_pred_inv = test_model(modelLSTF, X_test, y_test, scaler)\n","        \n","        results[dataset][pred_len] = {\n","            'MAE': mae,\n","            'RMSE': rmse\n","        }"]},{"cell_type":"code","execution_count":45,"metadata":{"execution":{"iopub.execute_input":"2024-07-19T14:05:06.357465Z","iopub.status.busy":"2024-07-19T14:05:06.357069Z","iopub.status.idle":"2024-07-19T14:05:06.375710Z","shell.execute_reply":"2024-07-19T14:05:06.374887Z","shell.execute_reply.started":"2024-07-19T14:05:06.357435Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th></th>\n","      <th>MAE</th>\n","      <th>RMSE</th>\n","    </tr>\n","    <tr>\n","      <th>Dataset</th>\n","      <th>Prediction Length</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th rowspan=\"4\" valign=\"top\">exchange_rate</th>\n","      <th>96</th>\n","      <td>0.044368</td>\n","      <td>0.059844</td>\n","    </tr>\n","    <tr>\n","      <th>192</th>\n","      <td>0.054688</td>\n","      <td>0.073013</td>\n","    </tr>\n","    <tr>\n","      <th>336</th>\n","      <td>0.079542</td>\n","      <td>0.105306</td>\n","    </tr>\n","    <tr>\n","      <th>720</th>\n","      <td>0.185081</td>\n","      <td>0.224984</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"3\" valign=\"top\">traffic</th>\n","      <th>96</th>\n","      <td>0.040704</td>\n","      <td>0.078620</td>\n","    </tr>\n","    <tr>\n","      <th>192</th>\n","      <td>0.037695</td>\n","      <td>0.075344</td>\n","    </tr>\n","    <tr>\n","      <th>336</th>\n","      <td>0.039054</td>\n","      <td>0.075822</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"4\" valign=\"top\">electricity</th>\n","      <th>96</th>\n","      <td>0.054440</td>\n","      <td>0.080014</td>\n","    </tr>\n","    <tr>\n","      <th>192</th>\n","      <td>0.058545</td>\n","      <td>0.082661</td>\n","    </tr>\n","    <tr>\n","      <th>336</th>\n","      <td>0.056093</td>\n","      <td>0.081940</td>\n","    </tr>\n","    <tr>\n","      <th>720</th>\n","      <td>0.058820</td>\n","      <td>0.084733</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                      MAE      RMSE\n","Dataset       Prediction Length                    \n","exchange_rate 96                 0.044368  0.059844\n","              192                0.054688  0.073013\n","              336                0.079542  0.105306\n","              720                0.185081  0.224984\n","traffic       96                 0.040704  0.078620\n","              192                0.037695  0.075344\n","              336                0.039054  0.075822\n","electricity   96                 0.054440  0.080014\n","              192                0.058545  0.082661\n","              336                0.056093  0.081940\n","              720                0.058820  0.084733"]},"execution_count":45,"metadata":{},"output_type":"execute_result"}],"source":["# Creating a DataFrame from the results dictionary\n","multi_index = pd.MultiIndex.from_tuples(\n","    [(dataset, pred_len) for dataset in results for pred_len in results[dataset]],\n","    names=['Dataset', 'Prediction Length']\n",")\n","\n","df_results = pd.DataFrame(\n","    [(results[dataset][pred_len]['MAE'], results[dataset][pred_len]['RMSE'])\n","     for dataset in results for pred_len in results[dataset]],\n","    index=multi_index,\n","    columns=['MAE', 'RMSE']\n",")\n","\n","df_results"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-07-19T14:25:19.261564Z","iopub.status.busy":"2024-07-19T14:25:19.260739Z","iopub.status.idle":"2024-07-19T14:25:19.270220Z","shell.execute_reply":"2024-07-19T14:25:19.269400Z","shell.execute_reply.started":"2024-07-19T14:25:19.261526Z"},"trusted":true},"outputs":[],"source":["# Writing df_results to a csv file\n","df_results.to_csv('results_uni.csv')"]},{"cell_type":"markdown","metadata":{},"source":["# Multivariate TSs\n","\n","We first train the model only on the dataset that have multivariate Time Series.\n","\n","Each file is a single Time Serie that have multiple feature to  be predicted.\n","\n","In the same way that they do in the article, we will predict each feature separately using the LTSF-Linear model.\n","\n","Since the datasets are too long, in order to not let the computation time exploding for high prediction windows we take only the last 10000 datapoints."]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-07-19T14:26:58.234890Z","iopub.status.busy":"2024-07-19T14:26:58.234473Z","iopub.status.idle":"2024-07-19T14:26:58.239155Z","shell.execute_reply":"2024-07-19T14:26:58.238348Z","shell.execute_reply.started":"2024-07-19T14:26:58.234858Z"},"trusted":true},"outputs":[],"source":["# Multivariate TS datasets\n","\n","datasets_multi = ['weather', 'ETTh1', 'ETTm1']"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-19T14:56:00.858385Z","iopub.status.busy":"2024-07-19T14:56:00.857290Z","iopub.status.idle":"2024-07-19T15:09:54.201605Z","shell.execute_reply":"2024-07-19T15:09:54.200702Z","shell.execute_reply.started":"2024-07-19T14:56:00.858346Z"},"trusted":true},"outputs":[],"source":["# For each dataset, train the model for each prediction length\n","# and store the results in a dictionary that later will be converted into a datatframe \n","\n","results_multi = {}\n","\n","for dataset in datasets_multi:\n","\n","    print(\"\\nDataset: \", dataset)\n","\n","    df = pd.read_csv(dataset_path + dataset + '.csv', index_col='date', parse_dates=True)\n","    \n","    # Taking the last 10000 datapoints of the Time Serie\n","    df = df.iloc[-10000:,:]\n","\n","    # Scaling all the columns in the range[0, 1]\n","    scaler = MinMaxScaler()\n","    df = pd.DataFrame(scaler.fit_transform(df), columns=df.columns, index=df.index)\n","    \n","    results_multi[dataset] = {}\n","\n","    for pred_len in prediction_lengths:\n","\n","        print(70 * \"-\")\n","        print(f\"\\nTraining LTSF-Linear for prediction length: {pred_len}\")\n","\n","\n","        # For each prediction length, we train the model for each column of the dataset\n","        # And then we take the average of the MAE and RMSE of all the columns\n","        maes = []\n","        rmses = []\n","\n","        for col in df.columns:\n","            print(70 * \"-\")\n","            print(f\"\\nTraining for column: {col}\")            \n","            \n","            # Converting the dataframe to numpy arrays\n","            # such that the moel can be trained on it\n","            X, y = build_designMatrixAndPrediction(pd.DataFrame(df[col]), lookback_window, pred_len)\n","            \n","            # Split the data in 80% train and 20% test\n","            train_size = int(len(X) * 0.8)\n","            X_train, X_test = torch.FloatTensor(X[:train_size]), torch.FloatTensor(X[train_size:])\n","            y_train, y_test = torch.FloatTensor(y[:train_size]), torch.FloatTensor(y[train_size:])\n","            \n","            # Initializing and training the model\n","            modelLSTF = LTSFLinear(lookback_window, prediction_length = pred_len)\n","            \n","            train_model(modelLSTF, X_train, y_train, epochs = 50, batch_size = 32)\n","            \n","            # Testing the model and saving its metrics\n","            mae, rmse, y_test_inv, y_pred_inv = test_model(modelLSTF, X_test, y_test, scaler)\n","            maes.append(mae)\n","            rmses.append(rmse)\n","        \n","        # Saving the average of the MAE and RMSE of all the columns\n","        # In the dictionary\n","        results_multi[dataset][pred_len] = {\n","            'MAE': np.mean(maes),\n","            'RMSE': np.mean(rmses)\n","        }\n"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-07-19T15:17:27.094620Z","iopub.status.busy":"2024-07-19T15:17:27.094222Z","iopub.status.idle":"2024-07-19T15:17:27.107571Z","shell.execute_reply":"2024-07-19T15:17:27.106934Z","shell.execute_reply.started":"2024-07-19T15:17:27.094588Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th></th>\n","      <th>MAE</th>\n","      <th>RMSE</th>\n","    </tr>\n","    <tr>\n","      <th>Dataset</th>\n","      <th>Prediction Length</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th rowspan=\"4\" valign=\"top\">weather</th>\n","      <th>96</th>\n","      <td>0.089227</td>\n","      <td>0.120001</td>\n","    </tr>\n","    <tr>\n","      <th>192</th>\n","      <td>0.108004</td>\n","      <td>0.144456</td>\n","    </tr>\n","    <tr>\n","      <th>336</th>\n","      <td>0.143208</td>\n","      <td>0.183607</td>\n","    </tr>\n","    <tr>\n","      <th>720</th>\n","      <td>0.200576</td>\n","      <td>0.245031</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"4\" valign=\"top\">ETTh1</th>\n","      <th>96</th>\n","      <td>0.076808</td>\n","      <td>0.104071</td>\n","    </tr>\n","    <tr>\n","      <th>192</th>\n","      <td>0.096826</td>\n","      <td>0.125046</td>\n","    </tr>\n","    <tr>\n","      <th>336</th>\n","      <td>0.109616</td>\n","      <td>0.139671</td>\n","    </tr>\n","    <tr>\n","      <th>720</th>\n","      <td>0.120480</td>\n","      <td>0.155150</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"4\" valign=\"top\">ETTm1</th>\n","      <th>96</th>\n","      <td>0.073092</td>\n","      <td>0.096906</td>\n","    </tr>\n","    <tr>\n","      <th>192</th>\n","      <td>0.083562</td>\n","      <td>0.107376</td>\n","    </tr>\n","    <tr>\n","      <th>336</th>\n","      <td>0.087728</td>\n","      <td>0.111352</td>\n","    </tr>\n","    <tr>\n","      <th>720</th>\n","      <td>0.095922</td>\n","      <td>0.121720</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                MAE      RMSE\n","Dataset Prediction Length                    \n","weather 96                 0.089227  0.120001\n","        192                0.108004  0.144456\n","        336                0.143208  0.183607\n","        720                0.200576  0.245031\n","ETTh1   96                 0.076808  0.104071\n","        192                0.096826  0.125046\n","        336                0.109616  0.139671\n","        720                0.120480  0.155150\n","ETTm1   96                 0.073092  0.096906\n","        192                0.083562  0.107376\n","        336                0.087728  0.111352\n","        720                0.095922  0.121720"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["# Creating a DataFrame from the results_multi dictionary\n","multi_index = pd.MultiIndex.from_tuples(\n","    [(dataset, pred_len) for dataset in results_multi for pred_len in results_multi[dataset]],\n","    names=['Dataset', 'Prediction Length']\n",")\n","\n","df_results_multi = pd.DataFrame(\n","    [(results_multi[dataset][pred_len]['MAE'], results_multi[dataset][pred_len]['RMSE'])\n","     for dataset in results_multi for pred_len in results_multi[dataset]],\n","    index=multi_index,\n","    columns=['MAE', 'RMSE']\n",")\n","\n","df_results_multi"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-07-19T15:35:39.310167Z","iopub.status.busy":"2024-07-19T15:35:39.309776Z","iopub.status.idle":"2024-07-19T15:35:39.328661Z","shell.execute_reply":"2024-07-19T15:35:39.327571Z","shell.execute_reply.started":"2024-07-19T15:35:39.310125Z"},"trusted":true},"outputs":[],"source":["# Writing df_results_multi to a csv file\n","df_results_multi.to_csv('results_multi.csv')"]},{"cell_type":"markdown","metadata":{},"source":["# Finally merge the two dataframes with the metrics"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-07-19T15:17:54.893038Z","iopub.status.busy":"2024-07-19T15:17:54.892414Z","iopub.status.idle":"2024-07-19T15:17:54.904196Z","shell.execute_reply":"2024-07-19T15:17:54.903354Z","shell.execute_reply.started":"2024-07-19T15:17:54.892995Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th></th>\n","      <th>MAE</th>\n","      <th>RMSE</th>\n","    </tr>\n","    <tr>\n","      <th>Dataset</th>\n","      <th>Prediction Length</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th rowspan=\"4\" valign=\"top\">electricity</th>\n","      <th>96</th>\n","      <td>0.054440</td>\n","      <td>0.080014</td>\n","    </tr>\n","    <tr>\n","      <th>192</th>\n","      <td>0.058545</td>\n","      <td>0.082661</td>\n","    </tr>\n","    <tr>\n","      <th>336</th>\n","      <td>0.056093</td>\n","      <td>0.081940</td>\n","    </tr>\n","    <tr>\n","      <th>720</th>\n","      <td>0.058820</td>\n","      <td>0.084733</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"4\" valign=\"top\">exchange_rate</th>\n","      <th>96</th>\n","      <td>0.044368</td>\n","      <td>0.059844</td>\n","    </tr>\n","    <tr>\n","      <th>192</th>\n","      <td>0.054688</td>\n","      <td>0.073013</td>\n","    </tr>\n","    <tr>\n","      <th>336</th>\n","      <td>0.079542</td>\n","      <td>0.105306</td>\n","    </tr>\n","    <tr>\n","      <th>720</th>\n","      <td>0.185081</td>\n","      <td>0.224984</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"4\" valign=\"top\">traffic</th>\n","      <th>96</th>\n","      <td>0.040704</td>\n","      <td>0.078620</td>\n","    </tr>\n","    <tr>\n","      <th>192</th>\n","      <td>0.037695</td>\n","      <td>0.075344</td>\n","    </tr>\n","    <tr>\n","      <th>336</th>\n","      <td>0.039054</td>\n","      <td>0.075822</td>\n","    </tr>\n","    <tr>\n","      <th>720</th>\n","      <td>0.053482</td>\n","      <td>0.090758</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"4\" valign=\"top\">weather</th>\n","      <th>96</th>\n","      <td>0.089227</td>\n","      <td>0.120001</td>\n","    </tr>\n","    <tr>\n","      <th>192</th>\n","      <td>0.108004</td>\n","      <td>0.144456</td>\n","    </tr>\n","    <tr>\n","      <th>336</th>\n","      <td>0.143208</td>\n","      <td>0.183607</td>\n","    </tr>\n","    <tr>\n","      <th>720</th>\n","      <td>0.200576</td>\n","      <td>0.245031</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"4\" valign=\"top\">ETTh1</th>\n","      <th>96</th>\n","      <td>0.076808</td>\n","      <td>0.104071</td>\n","    </tr>\n","    <tr>\n","      <th>192</th>\n","      <td>0.096826</td>\n","      <td>0.125046</td>\n","    </tr>\n","    <tr>\n","      <th>336</th>\n","      <td>0.109616</td>\n","      <td>0.139671</td>\n","    </tr>\n","    <tr>\n","      <th>720</th>\n","      <td>0.120480</td>\n","      <td>0.155150</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"4\" valign=\"top\">ETTm1</th>\n","      <th>96</th>\n","      <td>0.073092</td>\n","      <td>0.096906</td>\n","    </tr>\n","    <tr>\n","      <th>192</th>\n","      <td>0.083562</td>\n","      <td>0.107376</td>\n","    </tr>\n","    <tr>\n","      <th>336</th>\n","      <td>0.087728</td>\n","      <td>0.111352</td>\n","    </tr>\n","    <tr>\n","      <th>720</th>\n","      <td>0.095922</td>\n","      <td>0.121720</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                      MAE      RMSE\n","Dataset       Prediction Length                    \n","electricity   96                 0.054440  0.080014\n","              192                0.058545  0.082661\n","              336                0.056093  0.081940\n","              720                0.058820  0.084733\n","exchange_rate 96                 0.044368  0.059844\n","              192                0.054688  0.073013\n","              336                0.079542  0.105306\n","              720                0.185081  0.224984\n","traffic       96                 0.040704  0.078620\n","              192                0.037695  0.075344\n","              336                0.039054  0.075822\n","              720                0.053482  0.090758\n","weather       96                 0.089227  0.120001\n","              192                0.108004  0.144456\n","              336                0.143208  0.183607\n","              720                0.200576  0.245031\n","ETTh1         96                 0.076808  0.104071\n","              192                0.096826  0.125046\n","              336                0.109616  0.139671\n","              720                0.120480  0.155150\n","ETTm1         96                 0.073092  0.096906\n","              192                0.083562  0.107376\n","              336                0.087728  0.111352\n","              720                0.095922  0.121720"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["df_results_final = pd.concat([df_results, df_results_multi])\n","df_results_final"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-07-19T15:17:43.513922Z","iopub.status.busy":"2024-07-19T15:17:43.513371Z","iopub.status.idle":"2024-07-19T15:17:43.521166Z","shell.execute_reply":"2024-07-19T15:17:43.520432Z","shell.execute_reply.started":"2024-07-19T15:17:43.513889Z"},"trusted":true},"outputs":[],"source":["# Writing the results to file\n","df_results_final.to_csv('results_LTSF_Linear.csv')"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":5404447,"sourceId":8975922,"sourceType":"datasetVersion"}],"dockerImageVersionId":30748,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
